{"cells":[{"cell_type":"markdown","metadata":{"id":"BBgNOgHRS1FW"},"source":["# Flight Fare Prediction Project\n","1. As first step, we load our `FlightFare_Dataset` from Project Directory, using Pandas `read_excel` method\n","2. Then, we perform Feature Exploration and Engineering to transform our dataset\n","3. Once done, we use a Feature Selection technique to select the most important features\n","4. At this point, we train a Random Forest Regressor Model\n","5. As next step, we do hyper-parameter tuning (using `RandomGridSearch`) to build the best model\n","6. Finally, we export Model `.pkl` file back to Project Directory\n","7. Towards the end, we proceed to Model Deployment step"]},{"cell_type":"markdown","metadata":{"id":"duacQMllNqSn"},"source":["## Set up Environment"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1690834320111,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"vcrlrO11S1FZ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","import seaborn as sns\n","sns.set()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25090,"status":"ok","timestamp":1690834345703,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"YEDd3kzaOMCw","outputId":"3a1e3295-b9b7-4c6c-8dee-a9899edb464a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive - applicable, if working on Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1690834345704,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"-PzSLmcHNwSe","outputId":"ccb32b17-6758-4bca-e6a8-75c551671d68"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["# Set Working Directory - if working on Google Drive\n","%cd /content/drive/MyDrive/Colab Notebooks\n","# # Set Working Directory - if working on Local Machine\n","# import os\n","# os.chdir('/Users//replace_me')"]},{"cell_type":"markdown","metadata":{"id":"bFGnop_jS1Fa"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":16,"status":"error","timestamp":1690834345705,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"0Hbzcmp5S1Fb","outputId":"c7c1d56d-7618-4ba9-ca9c-7b71614516cc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Airline</th>\n","      <th>Date_of_Journey</th>\n","      <th>Source</th>\n","      <th>Destination</th>\n","      <th>Route</th>\n","      <th>Dep_Time</th>\n","      <th>Arrival_Time</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PIA</td>\n","      <td>24/03/2023</td>\n","      <td>Peshawar</td>\n","      <td>Afghanistan: Kabul</td>\n","      <td>PEW→Kabul</td>\n","      <td>22:20</td>\n","      <td>01:10 22 Mar</td>\n","      <td>45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>111152.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PIA</td>\n","      <td>2023-01-05 00:00:00</td>\n","      <td>Islamabad</td>\n","      <td>Bahrain</td>\n","      <td>ISB →BAH</td>\n","      <td>05:50</td>\n","      <td>13:15</td>\n","      <td>3 Hours</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>20956.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PIA</td>\n","      <td>2023-09-06 00:00:00</td>\n","      <td>Karachi</td>\n","      <td>Bahrain</td>\n","      <td>KHI→BAH</td>\n","      <td>09:25</td>\n","      <td>04:25 10 Jun</td>\n","      <td>2 Hours</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>56976.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PIA</td>\n","      <td>2023-12-05 00:00:00</td>\n","      <td>Karachi</td>\n","      <td>Bangladesh (Dhaka)</td>\n","      <td>KHI→DAC</td>\n","      <td>18:05</td>\n","      <td>23:30</td>\n","      <td>2 Hours 45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>94139.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PIA</td>\n","      <td>2023-01-03 00:00:00</td>\n","      <td>Lahore</td>\n","      <td>Bangladesh (Dhaka)</td>\n","      <td>LHE→DAC</td>\n","      <td>16:50</td>\n","      <td>21:35</td>\n","      <td>2 Hours 45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>219958.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Airline      Date_of_Journey     Source         Destination      Route  \\\n","0     PIA           24/03/2023   Peshawar  Afghanistan: Kabul  PEW→Kabul   \n","1     PIA  2023-01-05 00:00:00  Islamabad             Bahrain   ISB →BAH   \n","2     PIA  2023-09-06 00:00:00    Karachi             Bahrain    KHI→BAH   \n","3     PIA  2023-12-05 00:00:00    Karachi  Bangladesh (Dhaka)    KHI→DAC   \n","4     PIA  2023-01-03 00:00:00    Lahore   Bangladesh (Dhaka)    LHE→DAC   \n","\n","  Dep_Time  Arrival_Time            Duration Total_Stops Additional_Info  \\\n","0    22:20  01:10 22 Mar          45 Minutes    non-stop         No info   \n","1    05:50         13:15             3 Hours    non-stop         No info   \n","2    09:25  04:25 10 Jun             2 Hours    non-stop         No info   \n","3    18:05         23:30  2 Hours 45 Minutes    non-stop         No info   \n","4    16:50         21:35  2 Hours 45 Minutes    non-stop         No info   \n","\n","      Price  \n","0  111152.0  \n","1   20956.0  \n","2   56976.0  \n","3   94139.0  \n","4  219958.0  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# Load dataset from Project folder\n","\n","dataset = pd.read_excel(\"Synthesized Data revised.xlsx\")\n","\n","# To stretch head function output to the notebook width\n","pd.set_option('display.max_columns', None)\n","\n","dataset.head()"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1690834345707,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"slLEP_6QS1Fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 371 entries, 0 to 370\n","Data columns (total 11 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   Airline          371 non-null    object \n"," 1   Date_of_Journey  371 non-null    object \n"," 2   Source           371 non-null    object \n"," 3   Destination      371 non-null    object \n"," 4   Route            371 non-null    object \n"," 5   Dep_Time         371 non-null    object \n"," 6   Arrival_Time     371 non-null    object \n"," 7   Duration         371 non-null    object \n"," 8   Total_Stops      371 non-null    object \n"," 9   Additional_Info  371 non-null    object \n"," 10  Price            371 non-null    float64\n","dtypes: float64(1), object(10)\n","memory usage: 32.0+ KB\n"]}],"source":["dataset.info()       # Print Data Types"]},{"cell_type":"markdown","metadata":{"id":"Z2ABOEWcvUs4"},"source":["### Check for missing values"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1690834345709,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"nounGdRWS1Fd"},"outputs":[{"data":{"text/plain":["Airline            0\n","Date_of_Journey    0\n","Source             0\n","Destination        0\n","Route              0\n","Dep_Time           0\n","Arrival_Time       0\n","Duration           0\n","Total_Stops        0\n","Additional_Info    0\n","Price              0\n","dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["dataset.isnull().sum()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1690834345711,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"rkesT0mPS1Fd"},"outputs":[],"source":["dataset.dropna(inplace = True)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1690834345712,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"cLY6bzKoQUij"},"outputs":[{"data":{"text/plain":["Airline            0\n","Date_of_Journey    0\n","Source             0\n","Destination        0\n","Route              0\n","Dep_Time           0\n","Arrival_Time       0\n","Duration           0\n","Total_Stops        0\n","Additional_Info    0\n","Price              0\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["dataset.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"_3gT5bY7S1Fe"},"source":["## Feature Engineering"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1690834345713,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"VJFAzCADQ7lT"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Airline</th>\n","      <th>Date_of_Journey</th>\n","      <th>Source</th>\n","      <th>Destination</th>\n","      <th>Route</th>\n","      <th>Dep_Time</th>\n","      <th>Arrival_Time</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PIA</td>\n","      <td>24/03/2023</td>\n","      <td>Peshawar</td>\n","      <td>Afghanistan: Kabul</td>\n","      <td>PEW→Kabul</td>\n","      <td>22:20</td>\n","      <td>01:10 22 Mar</td>\n","      <td>45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>111152.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PIA</td>\n","      <td>2023-01-05 00:00:00</td>\n","      <td>Islamabad</td>\n","      <td>Bahrain</td>\n","      <td>ISB →BAH</td>\n","      <td>05:50</td>\n","      <td>13:15</td>\n","      <td>3 Hours</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>20956.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PIA</td>\n","      <td>2023-09-06 00:00:00</td>\n","      <td>Karachi</td>\n","      <td>Bahrain</td>\n","      <td>KHI→BAH</td>\n","      <td>09:25</td>\n","      <td>04:25 10 Jun</td>\n","      <td>2 Hours</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>56976.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PIA</td>\n","      <td>2023-12-05 00:00:00</td>\n","      <td>Karachi</td>\n","      <td>Bangladesh (Dhaka)</td>\n","      <td>KHI→DAC</td>\n","      <td>18:05</td>\n","      <td>23:30</td>\n","      <td>2 Hours 45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>94139.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PIA</td>\n","      <td>2023-01-03 00:00:00</td>\n","      <td>Lahore</td>\n","      <td>Bangladesh (Dhaka)</td>\n","      <td>LHE→DAC</td>\n","      <td>16:50</td>\n","      <td>21:35</td>\n","      <td>2 Hours 45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>219958.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Airline      Date_of_Journey     Source         Destination      Route  \\\n","0     PIA           24/03/2023   Peshawar  Afghanistan: Kabul  PEW→Kabul   \n","1     PIA  2023-01-05 00:00:00  Islamabad             Bahrain   ISB →BAH   \n","2     PIA  2023-09-06 00:00:00    Karachi             Bahrain    KHI→BAH   \n","3     PIA  2023-12-05 00:00:00    Karachi  Bangladesh (Dhaka)    KHI→DAC   \n","4     PIA  2023-01-03 00:00:00    Lahore   Bangladesh (Dhaka)    LHE→DAC   \n","\n","  Dep_Time  Arrival_Time            Duration Total_Stops Additional_Info  \\\n","0    22:20  01:10 22 Mar          45 Minutes    non-stop         No info   \n","1    05:50         13:15             3 Hours    non-stop         No info   \n","2    09:25  04:25 10 Jun             2 Hours    non-stop         No info   \n","3    18:05         23:30  2 Hours 45 Minutes    non-stop         No info   \n","4    16:50         21:35  2 Hours 45 Minutes    non-stop         No info   \n","\n","      Price  \n","0  111152.0  \n","1   20956.0  \n","2   56976.0  \n","3   94139.0  \n","4  219958.0  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["dataset.head()"]},{"cell_type":"markdown","metadata":{"id":"l9Mr_4zVYCd5"},"source":["### Handling Object Data\n","**`Date_of_Journey`, `Dep_Time`, `Arrival_Time`, `Duration` are object datatype.** To derive numeric features on these, we use pandas `to_datetime` method to convert object data type to datetime datatype.\n","\n","<span style=\"color: red;\">Attribute `.dt.day`  will extract day from the date</span>\\\n","<span style=\"color: red;\">Attribute `.dt.month` will extract  month from that date</span>"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1690834345715,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"biASfcHxS1Fe"},"outputs":[],"source":["# split the Date of Journey column into day, month and year\n","dataset[\"Journey_day\"] = pd.to_datetime(dataset.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n","dataset[\"Journey_month\"] = pd.to_datetime(dataset.Date_of_Journey, format=\"%d/%m/%Y\").dt.month\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":24,"status":"aborted","timestamp":1690834345716,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"rT6s-eEBS1Ff"},"outputs":[],"source":["# Since we have converted Date_of_Journey column into integers, Now we can drop as it is of no use.\n","dataset.drop([\"Date_of_Journey\"], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":24,"status":"aborted","timestamp":1690834345717,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"Z4dI5r9pS1Ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Sagar\\AppData\\Local\\Temp\\ipykernel_6532\\2016018360.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  dataset['Dep_Time'] = pd.to_datetime(dataset['Dep_Time'])\n"]}],"source":["# Departure time is when a plane leaves the gate.\n","# Similar to Date_of_Journey we can extract values from Dep_Time\n","# Extracting Hours\n","dataset['Dep_Time'] = pd.to_datetime(dataset['Dep_Time'])\n","dataset['Dep_hour'] = dataset['Dep_Time'].dt.hour\n","# Extracting Minutes\n","dataset['Dep_min'] = dataset['Dep_Time'].dt.minute\n","# Now we drop Dep_Time as it is of no use\n","dataset.drop([\"Dep_Time\"], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":26370,"status":"aborted","timestamp":1690834345718,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"5D9PH9U7S1Fg"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Sagar\\AppData\\Local\\Temp\\ipykernel_6532\\877592423.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  dataset[\"arrival_hour\"] = pd.to_datetime(dataset[\"Arrival_Time\"]).dt.hour\n","C:\\Users\\Sagar\\AppData\\Local\\Temp\\ipykernel_6532\\877592423.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  dataset[\"arrival_min\"] = pd.to_datetime(dataset[\"Arrival_Time\"]).dt.minute\n"]}],"source":["# Arrival time is when the plane pulls up to the gate.\n","# Similar to Date_of_Journey we can extract values from Arrival_Time\n","\n","# Extracting Hours\n","dataset[\"arrival_hour\"] = pd.to_datetime(dataset[\"Arrival_Time\"]).dt.hour\n","# Extracting Minutes\n","dataset[\"arrival_min\"] = pd.to_datetime(dataset[\"Arrival_Time\"]).dt.minute\n","# Now we can drop Arrival_Time as it is of no use\n","dataset.drop([\"Arrival_Time\"], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":26360,"status":"aborted","timestamp":1690834345718,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"cEhqWAvuS1Fg"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Airline</th>\n","      <th>Source</th>\n","      <th>Destination</th>\n","      <th>Route</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","      <th>Journey_day</th>\n","      <th>Journey_month</th>\n","      <th>Dep_hour</th>\n","      <th>Dep_min</th>\n","      <th>arrival_hour</th>\n","      <th>arrival_min</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PIA</td>\n","      <td>Peshawar</td>\n","      <td>Afghanistan: Kabul</td>\n","      <td>PEW→Kabul</td>\n","      <td>45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>111152.0</td>\n","      <td>24</td>\n","      <td>3</td>\n","      <td>22</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PIA</td>\n","      <td>Islamabad</td>\n","      <td>Bahrain</td>\n","      <td>ISB →BAH</td>\n","      <td>3 Hours</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>20956.0</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>50</td>\n","      <td>13</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PIA</td>\n","      <td>Karachi</td>\n","      <td>Bahrain</td>\n","      <td>KHI→BAH</td>\n","      <td>2 Hours</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>56976.0</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>25</td>\n","      <td>4</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PIA</td>\n","      <td>Karachi</td>\n","      <td>Bangladesh (Dhaka)</td>\n","      <td>KHI→DAC</td>\n","      <td>2 Hours 45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>94139.0</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>18</td>\n","      <td>5</td>\n","      <td>23</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PIA</td>\n","      <td>Lahore</td>\n","      <td>Bangladesh (Dhaka)</td>\n","      <td>LHE→DAC</td>\n","      <td>2 Hours 45 Minutes</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>219958.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>16</td>\n","      <td>50</td>\n","      <td>21</td>\n","      <td>35</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Airline     Source         Destination      Route            Duration  \\\n","0     PIA   Peshawar  Afghanistan: Kabul  PEW→Kabul          45 Minutes   \n","1     PIA  Islamabad             Bahrain   ISB →BAH             3 Hours   \n","2     PIA    Karachi             Bahrain    KHI→BAH             2 Hours   \n","3     PIA    Karachi  Bangladesh (Dhaka)    KHI→DAC  2 Hours 45 Minutes   \n","4     PIA    Lahore   Bangladesh (Dhaka)    LHE→DAC  2 Hours 45 Minutes   \n","\n","  Total_Stops Additional_Info     Price  Journey_day  Journey_month  Dep_hour  \\\n","0    non-stop         No info  111152.0           24              3        22   \n","1    non-stop         No info   20956.0            5              1         5   \n","2    non-stop         No info   56976.0            6              9         9   \n","3    non-stop         No info   94139.0            5             12        18   \n","4    non-stop         No info  219958.0            3              1        16   \n","\n","   Dep_min  arrival_hour  arrival_min  \n","0       20             1           10  \n","1       50            13           15  \n","2       25             4           25  \n","3        5            23           30  \n","4       50            21           35  "]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26358,"status":"aborted","timestamp":1690834345719,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"d0alujNSlZkK"},"outputs":[],"source":["# len('2h 50m'.split())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":26350,"status":"aborted","timestamp":1690834345720,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"0JqtBNwAS1Fg"},"outputs":[{"ename":"ValueError","evalue":"invalid literal for int() with base 10: '45 Minutes'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[40], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m duration_mins \u001b[39m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(duration)):\n\u001b[1;32m---> 18\u001b[0m     duration_hours\u001b[39m.\u001b[39mappend(\u001b[39mint\u001b[39;49m(duration[i]\u001b[39m.\u001b[39;49msplit(sep \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mh\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m0\u001b[39;49m]))    \u001b[39m# Extract hours from duration\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     duration_mins\u001b[39m.\u001b[39mappend(\u001b[39mint\u001b[39m(duration[i]\u001b[39m.\u001b[39msplit(sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))   \u001b[39m# Extracts only minutes from duration\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# Add duration_hours and duration_mins list to our dataset df\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '45 Minutes'"]}],"source":["# Duration is the time taken by plane to reach destination\n","# It is the difference betwen Arrival Time and Departure time\n","# Assigning and converting Duration column into list, for looping through\n","duration = list(dataset[\"Duration\"])\n","# In table above, Row Index=2, we have Duration = 19h (missing minutes)\n","# Looping through all duration values\n","# To ensure it has both hours & mins: 'xh ym'\n","for i in range(len(duration)):\n","    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n","        if \"Hours\" in duration[i]:\n","            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n","        else:\n","            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n","# Prepare separate duration_hours and duration_mins lists\n","duration_hours = []\n","duration_mins = []\n","for i in range(len(duration)):\n","    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n","    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n","\n","# Add duration_hours and duration_mins list to our dataset df\n","dataset[\"Duration_hours\"] = duration_hours\n","dataset[\"Duration_mins\"] = duration_mins\n","# Drop Duration column from the dataset\n","dataset.drop([\"Duration\"], axis = 1, inplace = True)\n","\n","dataset.head()"]},{"cell_type":"markdown","metadata":{"id":"X-A9XYVMS1Fh"},"source":["### Handling Categorical Data\n","\n","**`Airline`, `Source`, `Destination`, `Route`, `Total_Stops`, `Additional_Info` are all categorical.** One can find many ways to handle categorical data, like:\n","1. <span style=\"color: blue;\">**Nominal data**</span> --> data is not in any order --> <span style=\"color: green;\">**OneHotEncoder**</span> is used in this case\n","2. <span style=\"color: blue;\">**Ordinal data**</span> --> data is in order --> <span style=\"color: green;\">**LabelEncoder**</span> is used in this case"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26345,"status":"aborted","timestamp":1690834345721,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"SUQOO8irS1Fh"},"outputs":[],"source":["# Feature engineering on: Airline\n","dataset[\"Airline\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26340,"status":"aborted","timestamp":1690834345722,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"dkJgriADe4jh"},"outputs":[],"source":["# As Airline is Nominal Categorical data we will perform OneHotEncoding\n","Airline = dataset[[\"Airline\"]]\n","Current_Airline_List = Airline['Airline']\n","New_Airline_List = []\n","\n","for carrier in Current_Airline_List:\n","  if carrier in ['Jet Airways', 'IndiGo', 'Air India', 'SpiceJet',\n","       'Multiple carriers', 'GoAir', 'Vistara', 'Air Asia']:\n","    New_Airline_List.append(carrier)\n","  else:\n","    New_Airline_List.append('Other')\n","\n","Airline['Airline'] = pd.DataFrame(New_Airline_List)\n","Airline['Airline'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26333,"status":"aborted","timestamp":1690834345723,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"soPl0ATSS1Fh"},"outputs":[],"source":["Airline = pd.get_dummies(Airline, drop_first= True)\n","Airline.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":43,"status":"aborted","timestamp":1690834346331,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"mPeuBE9OS1Fi"},"outputs":[],"source":["# Feature engineering on: Source\n","dataset[\"Source\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1690834346331,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"AJggB_CdS1Fi"},"outputs":[],"source":["# As Source is Nominal Categorical data we will perform OneHotEncoding\n","Source = dataset[[\"Source\"]]\n","Source = pd.get_dummies(Source, drop_first= True)\n","# drop_first= True means we drop the first column to prevent multicollinearity\n","Source.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":42,"status":"aborted","timestamp":1690834346332,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"WvrboCFCS1Fi"},"outputs":[],"source":["# Feature engineering on: Destination\n","dataset[\"Destination\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1690834346333,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"MEUP2BEO2TBq"},"outputs":[],"source":["# Renaming destination 'New Delhi' to 'Delhi' - to match with Source\n","Destination = dataset[[\"Destination\"]]\n","Current_Destination_List = Destination['Destination']\n","New_Destination_List = []\n","\n","for value in Current_Destination_List:\n","  if value in ['New Delhi']:\n","    New_Destination_List.append('Delhi')\n","  else:\n","    New_Destination_List.append(value)\n","\n","Destination['Destination'] = pd.DataFrame(New_Destination_List)\n","\n","# As Destination is Nominal Categorical data we will perform OneHotEncoding\n","Destination = pd.get_dummies(Destination, drop_first = True)\n","Destination.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1690834346334,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"Vg2gE6rxS1Fi"},"outputs":[],"source":["# Additional_Info contains almost 80% no_info\n","# Route and Total_Stops are related to each other\n","dataset.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1690834346335,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"TMiL6MZ4S1Fi"},"outputs":[],"source":["# Feature engineering on: Total_Stops\n","dataset[\"Total_Stops\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1690834346335,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"myZ0fz8LS1Fi"},"outputs":[],"source":["# As this is case of Ordinal Categorical type we perform LabelEncoder\n","# Here Values are assigned with corresponding keys\n","dataset.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n","dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1690834346337,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"v_G3ZVrXS1Fj"},"outputs":[],"source":["# Concatenate dataframe --> train_data + Airline + Source + Destination\n","data_train = pd.concat([dataset, Airline, Source, Destination], axis = 1) # axis = 1 signifies column\n","data_train.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n","\n","data_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1690834346337,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"dOytf6t3S1Fj"},"outputs":[],"source":["data_train.shape"]},{"cell_type":"markdown","metadata":{"id":"SEP5wMxQS1Fk"},"source":["## Feature Selection\n","\n","Finding out the best feature which will contribute and have good relation with target variable.\n","Following are some of the feature selection methods:\n","\n","\n","1. <span style=\"color: purple;\">**feature_importance_**</span>: To check for relative feature importance\n","2. <span style=\"color: purple;\">**Variable Inflation Factor (VIF)**</span>: To check for multicollinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41,"status":"aborted","timestamp":1690834346338,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"A8jHpbjSS1Fk"},"outputs":[],"source":["# data_train.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":45,"status":"aborted","timestamp":1690834346342,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"wAWy6A20S1Fk"},"outputs":[],"source":["X = data_train.loc[:, ['Total_Stops', 'journey_day', 'journey_month', 'dep_hour',\n","       'dep_min', 'arrival_hour', 'arrival_min', 'Duration_hours',\n","       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_Other',\n","       'Airline_SpiceJet', 'Airline_Vistara', 'Source_Chennai', 'Source_Delhi',\n","       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',\n","       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata']]\n","y = data_train.iloc[:, 1]\n","\n","print(X.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"HeS_DjXc5ayE"},"source":["### feature_importance_"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46,"status":"aborted","timestamp":1690834346344,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"_R2HKxjwS1Fk"},"outputs":[],"source":["# Important feature using ExtraTreesRegressor\n","from sklearn.ensemble import ExtraTreesRegressor\n","selection = ExtraTreesRegressor()\n","selection.fit(X, y)\n","\n","print(selection.feature_importances_)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1690834346345,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"XDqTCwDTS1Fl"},"outputs":[],"source":["#plot graph of feature importances for better visualization\n","plt.figure(figsize = (12,8))\n","feat_importances = pd.Series(selection.feature_importances_, index=X.columns)\n","feat_importances.nlargest(25).plot(kind='barh')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hiqMNCUH50LT"},"source":["### VIF - Multicollinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1690834346347,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"E0vbxppVmuFr"},"outputs":[],"source":["# Checking for Multicollinearity\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","def calc_vif(z):\n","    # Calculating Variable Inflation Factor (VIF)\n","    vif = pd.DataFrame()\n","    vif[\"variables\"] = z.columns\n","    vif[\"VIF\"] = [variance_inflation_factor(z.values, i) for i in range(z.shape[1])]\n","    return(vif)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1690834346347,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"xbQuyvAamuwp"},"outputs":[],"source":["# Compute VIF on X\n","calc_vif(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":50,"status":"aborted","timestamp":1690834346349,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"EEejlvy4rjhI"},"outputs":[],"source":["# Drop 'Source_Delhi'\n","X = data_train.loc[:, ['Total_Stops', 'journey_day', 'journey_month', 'dep_hour',\n","       'dep_min', 'arrival_hour', 'arrival_min', 'Duration_hours',\n","       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_Other',\n","       'Airline_SpiceJet', 'Airline_Vistara', 'Source_Chennai',\n","       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',\n","       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata']]\n","X.head()"]},{"cell_type":"markdown","metadata":{"id":"NpdCnWZJS1Fl"},"source":["## Fit model - Random Forest\n","\n","1. Split dataset into train and test set in order to predict, w.r.t, X_test\n","2. If needed do scaling of data\n","    * Scaling is not required in Random forest\n","3. Train Model\n","4. Gauge Model Performance\n","5. In regression check **RSME** Score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":51,"status":"aborted","timestamp":1690834346350,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"Ot0B6DehS1Fl"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":50,"status":"aborted","timestamp":1690834346350,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"RmuPTH6nS1Fl"},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","rf_reg = RandomForestRegressor()\n","rf_reg.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"txn0DDgf8Da-"},"source":["### Model Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":51,"status":"aborted","timestamp":1690834346351,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"qykQeIpsS1Fl"},"outputs":[],"source":["print('Model Performance on Training Set:', round(rf_reg.score(X_train, y_train)*100,2))\n","print('Model Performance on Test Set:', round(rf_reg.score(X_test, y_test)*100,2))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1690834346352,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"w0fLHmzsS1Fl"},"outputs":[],"source":["# Plot performance graph\n","y_pred = rf_reg.predict(X_test)\n","plt.scatter(y_test, y_pred, alpha = 0.5)\n","plt.xlabel(\"y_test\")\n","plt.ylabel(\"y_pred\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":52,"status":"aborted","timestamp":1690834346353,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"C8WI7In0S1Fl"},"outputs":[],"source":["# Model Error Values\n","print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n","print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n","print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n","# RMSE = sqrt((PV-OV)^2/n)\n","print('Normalized RMSE ', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred))/(max(y_test)-min(y_test)),2))\n","# RMSE/(max(DV)-min(DV))\n","print('Max Value: ', max(y), '\\nMin Value: ', min(y))"]},{"cell_type":"markdown","metadata":{"id":"pvYeHQpcS1Fn"},"source":["### Save the model .pkl"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":53,"status":"aborted","timestamp":1690834346354,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"h4ggjhPHS1Fn"},"outputs":[],"source":["import pickle\n","# open a file, where you ant to store the data\n","file = open('c1_flight_rf.pkl', 'wb')\n","# dump information to that file\n","pickle.dump(rf_reg, file)"]},{"cell_type":"markdown","metadata":{"id":"dfw9ROxQs1HM"},"source":["# Prediction on Unseen data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":54,"status":"aborted","timestamp":1690834346355,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"zISCE_BYuh27"},"outputs":[],"source":["import pickle\n","path = 'c1_flight_rf.pkl'\n","model = open(path,'rb')\n","rf_model = pickle.load(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":55,"status":"aborted","timestamp":1690834346357,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"lnUogtuHs4T6"},"outputs":[],"source":["unseen_dataset = pd.read_excel(\"./a2_Unseen_Dataset.xlsx\")\n","unseen_dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":59,"status":"aborted","timestamp":1690834346361,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"60tQPbrftMIY"},"outputs":[],"source":["# Perform feature engineering on object dt variables\n","# Feature Engineering on: 'Date_of_Journey'\n","unseen_dataset[\"journey_day\"] = pd.to_datetime(unseen_dataset.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n","unseen_dataset[\"journey_month\"] = pd.to_datetime(unseen_dataset[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month\n","unseen_dataset.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n","\n","# Feature Engineering on: 'Dep_Time'\n","unseen_dataset[\"dep_hour\"] = pd.to_datetime(unseen_dataset[\"Dep_Time\"]).dt.hour\n","unseen_dataset[\"dep_min\"] = pd.to_datetime(unseen_dataset[\"Dep_Time\"]).dt.minute\n","unseen_dataset.drop([\"Dep_Time\"], axis = 1, inplace = True)\n","\n","# Feature Engineering on: 'Arrival_Time'\n","unseen_dataset[\"arrival_hour\"] = pd.to_datetime(unseen_dataset[\"Arrival_Time\"]).dt.hour\n","unseen_dataset[\"arrival_min\"] = pd.to_datetime(unseen_dataset[\"Arrival_Time\"]).dt.minute\n","unseen_dataset.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n","\n","# Feature Engineering on: 'Duration'\n","duration = list(unseen_dataset[\"Duration\"])\n","for i in range(len(duration)):\n","    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n","        if \"h\" in duration[i]:\n","            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n","        else:\n","            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n","duration_hours = []\n","duration_mins = []\n","for i in range(len(duration)):\n","    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n","    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n","unseen_dataset[\"Duration_hours\"] = duration_hours\n","unseen_dataset[\"Duration_mins\"] = duration_mins\n","unseen_dataset.drop([\"Duration\"], axis = 1, inplace = True)\n","\n","\n","# Perform feature engineering on Categorical dt variables\n","# Feature Engineering on: 'Airline'\n","Airline = unseen_dataset[[\"Airline\"]]\n","New_Airline_List = []\n","Current_Airline_List = Airline['Airline']\n","for carrier in Current_Airline_List:\n","  if carrier in ['IndiGo', 'Air India', 'Jet Airways', 'SpiceJet',\n","       'Multiple carriers', 'GoAir', 'Vistara', 'Air Asia']:\n","    New_Airline_List.append(carrier)\n","  else:\n","    New_Airline_List.append('Other')\n","Airline['Airline'] = pd.DataFrame(New_Airline_List)\n","Airline = pd.get_dummies(Airline, drop_first= True)\n","\n","# Feature Engineering on: 'Source'\n","Source = unseen_dataset[[\"Source\"]]\n","Source = pd.get_dummies(Source, drop_first= True)\n","Source.head()\n","\n","# Feature Engineering on: 'Destination'\n","Destination = unseen_dataset[[\"Destination\"]]\n","Current_Destination_List = Destination['Destination']\n","New_Destination_List = []\n","for value in Current_Destination_List:\n","  if value in ['New Delhi']:\n","    New_Destination_List.append('Delhi')\n","  else:\n","    New_Destination_List.append(value)\n","Destination['Destination'] = pd.DataFrame(New_Destination_List)\n","Destination['Destination'].value_counts()\n","Destination = pd.get_dummies(Destination, drop_first = True)\n","Destination.head()\n","\n","# Feature Engineering on: 'Route', 'Additional_Info\n","unseen_dataset.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n","\n","# Feature Engineering on: 'Total_Stops'\n","unseen_dataset.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n","\n","# Concatenate dataframe --> train_data + Airline + Source + Destination\n","data_test = pd.concat([unseen_dataset, Airline, Source, Destination], axis = 1)\n","data_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n","\n","# See how the test dataset looks\n","data_test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":59,"status":"aborted","timestamp":1690834346361,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"RMyw5gG_uY8n"},"outputs":[],"source":["# Drop 'Source_Delhi'\n","X_unseen = data_test.loc[:, ['Total_Stops', 'journey_day', 'journey_month', 'dep_hour',\n","       'dep_min', 'arrival_hour', 'arrival_min', 'Duration_hours',\n","       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_Other',\n","       'Airline_SpiceJet', 'Airline_Vistara', 'Source_Chennai',\n","       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',\n","       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata']]\n","y_unseen = data_test.iloc[:, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1690834346363,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"Jkq9q2s_yGMG"},"outputs":[],"source":["# Predictions on unseen data\n","y_pred = rf_model.predict(X_unseen)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1690834346363,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"2S64OqbzF1Dt"},"outputs":[],"source":["print('Normalized RMSE: ', round(np.sqrt(metrics.mean_squared_error(y_unseen, y_pred))/(max(y_unseen)-min(y_unseen)),2))\n","print('Max Value: ', max(y_unseen), '\\nMin Value: ', min(y_unseen))\n","print('R2 value: ', round(metrics.r2_score(y_unseen, y_pred),2))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1690834346364,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"6I3M-2O-yW3h"},"outputs":[],"source":["# writing model output file\n","df_y_pred = pd.DataFrame(y_pred,columns= ['Predicted Price'])\n","original_dataset = pd.read_excel(\"./a2_Unseen_Dataset.xlsx\")\n","dfx = pd.concat([original_dataset, df_y_pred], axis=1)\n","dfx.to_excel(\"c2_ModelOutput.xlsx\")\n","dfx.head()"]},{"cell_type":"markdown","metadata":{"id":"jWCd6yk9tvnB"},"source":["---\n","# In the next tutorial\n","---"]},{"cell_type":"markdown","metadata":{"id":"nZdw_DXFS1Fm"},"source":["## Hyperparameter Tuning\n","\n","\n","* Choose following method for hyperparameter tuning\n","    1. **RandomizedSearchCV** --> Fast\n","    2. **GridSearchCV**\n","* Assign hyperparameters in form of dictionary\n","* Fit the model\n","* Check best paramters and best score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1690834346365,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"EhHmVC9jS1Fm"},"outputs":[],"source":["from sklearn.model_selection import RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":62,"status":"aborted","timestamp":1690834346366,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"4foe6EnrS1Fm"},"outputs":[],"source":["#Randomized Search CV\n","# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n","# Number of features to consider at every split\n","max_features = ['auto', 'sqrt']\n","# Maximum number of levels in tree\n","max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10, 15, 100]\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = [1, 2, 5, 10]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":62,"status":"aborted","timestamp":1690834346366,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"8P1i--5yS1Fm"},"outputs":[],"source":["# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1690834346368,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"8sfhJeXpS1Fm"},"outputs":[],"source":["# Random search of parameters, using 5 fold cross validation,\n","# search across 100 different combinations\n","rf_random = RandomizedSearchCV(estimator = rf_reg, param_distributions = random_grid,\n","                               scoring='neg_mean_squared_error', n_iter = 10, cv = 5,\n","                               verbose=2, random_state=42, n_jobs = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1690834346368,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"I6o4FoG2S1Fm"},"outputs":[],"source":["# Model Training with Hyperparameter Tuning\n","rf_random.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1690834346369,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"OSbT_HsLS1Fm"},"outputs":[],"source":["rf_random.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1690834346371,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"rOsDYms0QrBY"},"outputs":[],"source":["# Plot Performance Chart\n","prediction = rf_random.predict(X_test)\n","plt.figure(figsize = (8,8))\n","plt.scatter(y_test, prediction, alpha = 0.5)\n","plt.xlabel(\"y_test\")\n","plt.ylabel(\"y_pred\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1690834346371,"user":{"displayName":"Kumar Sagar","userId":"05649922090385473700"},"user_tz":-300},"id":"hxl579dsQtZt"},"outputs":[],"source":["# RMSE/(max(DV)-min(DV))\n","print('R2 value: ', round(metrics.r2_score(y_test, prediction),2))\n","print('RMSE: ', round(np.sqrt(metrics.mean_squared_error(y_test, prediction)),2))\n","print('Normalized RMSE: ', round(np.sqrt(metrics.mean_squared_error(y_test, prediction))/(max(y_test)-min(y_test)),2))\n","print('Max Value: ', max(y_test), '\\nMin Value: ', min(y_test))"]}],"metadata":{"colab":{"collapsed_sections":["dfw9ROxQs1HM","jWCd6yk9tvnB"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
